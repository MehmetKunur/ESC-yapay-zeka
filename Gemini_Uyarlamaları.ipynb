{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehmetKunur/ESC-yapay-zeka/blob/main/Gemini_Uyarlamalar%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20CG0vfPmAXN"
      },
      "outputs": [],
      "source": [
        "pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cK7GTkm4pulc"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('MehmetKunur')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RSmdRY6jmlJv",
        "outputId": "fdd86850-c570-4d5a-946a-815f24eb3171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yapay zeka; bilgisayar sistemlerinin öğrenme, akıl yürütme ve problem çözme gibi insana özgü bilişsel yetenekleri taklit etmesini sağlayan teknolojidir.\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "client = genai.Client(api_key=userdata.get('MehmetKunur'))\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\", contents=\"Yapay Zeka Nedir? Bir Cümleyle Açıkla\"\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk_n7OfbmlZv",
        "outputId": "fd564d2d-7c82-43a2-a20c-3f4dfaf07a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yapay zeka, devasa veri yığınlarındaki kalıpları matematiksel algoritmalarla analiz ederek öğrenen ve bu deneyimlerle yeni durumlar hakkında tahminler yürüten veya kararlar veren bir sistemdir.\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('MehmetKunur'))\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"Yapay Zeka Naıl Çalışır? Bir Cümleyle Anlat\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_level=\"low\")\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xRN2EVty80rV",
        "outputId": "cdaa84a0-036d-4b9e-d74e-62b34067b8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='models/gemini-2.5-flash' display_name='Gemini 2.5 Flash' description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-pro' display_name='Gemini 2.5 Pro' description='Stable release (June 17th, 2025) of Gemini 2.5 Pro' version='2.5' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-exp-image-generation' display_name='Gemini 2.0 Flash (Image Generation) Experimental' description='Gemini 2.0 Flash (Image Generation) Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemma-3n-e2b-it' display_name='Gemma 3n E2B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=None top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-flash-latest' display_name='Gemini Flash Latest' description='Latest release of Gemini Flash' version='Gemini Flash Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-flash-lite-latest' display_name='Gemini Flash-Lite Latest' description='Latest release of Gemini Flash-Lite' version='Gemini Flash-Lite Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-pro-latest' display_name='Gemini Pro Latest' description='Latest release of Gemini Pro' version='Gemini Pro Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-lite' display_name='Gemini 2.5 Flash-Lite' description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-image' display_name='Nano Banana' description='Gemini 2.5 Flash Preview Image' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=32768 output_token_limit=32768 supported_actions=['generateContent', 'countTokens', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=1.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-2.5-flash-preview-09-2025' display_name='Gemini 2.5 Flash Preview Sep 2025' description='Gemini 2.5 Flash Preview Sep 2025' version='Gemini 2.5 Flash Preview 09-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-lite-preview-09-2025' display_name='Gemini 2.5 Flash-Lite Preview Sep 2025' description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite' version='2.5-preview-09-25' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-pro-preview' display_name='Gemini 3 Pro Preview' description='Gemini 3 Pro Preview' version='3-pro-preview-11-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-flash-preview' display_name='Gemini 3 Flash Preview' description='Gemini 3 Flash Preview' version='3-flash-preview-12-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-pro-image-preview' display_name='Nano Banana Pro' description='Gemini 3 Pro Image Preview' version='3.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=32768 supported_actions=['generateContent', 'countTokens', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=1.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/nano-banana-pro-preview' display_name='Nano Banana Pro' description='Gemini 3 Pro Image Preview' version='3.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=32768 supported_actions=['generateContent', 'countTokens', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=1.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-robotics-er-1.5-preview' display_name='Gemini Robotics-ER 1.5 Preview' description='Gemini Robotics-ER 1.5 Preview' version='1.5-preview' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-computer-use-preview-10-2025' display_name='Gemini 2.5 Computer Use Preview 10-2025' description='Gemini 2.5 Computer Use Preview 10-2025' version='Gemini 2.5 Computer Use Preview 10-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=65536 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/deep-research-pro-preview-12-2025' display_name='Deep Research Pro Preview (Dec-12-2025)' description='Preview release (December 12th, 2025) of Deep Research Pro' version='deepthink-exp-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=65536 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/gemini-embedding-001' display_name='Gemini Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None temperature=0.2 max_temperature=None top_p=1.0 top_k=40 thinking=None\n",
            "name='models/imagen-4.0-generate-preview-06-06' display_name='Imagen 4 (Preview)' description='Vertex served Imagen 4.0 model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/imagen-4.0-ultra-generate-preview-06-06' display_name='Imagen 4 Ultra (Preview)' description='Vertex served Imagen 4.0 ultra model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/imagen-4.0-generate-001' display_name='Imagen 4' description='Vertex served Imagen 4.0 model' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/imagen-4.0-ultra-generate-001' display_name='Imagen 4 Ultra' description='Vertex served Imagen 4.0 ultra model' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/imagen-4.0-fast-generate-001' display_name='Imagen 4 Fast' description='Vertex served Imagen 4.0 Fast model' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/veo-3.0-generate-001' display_name='Veo 3' description='Veo 3' version='3.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/veo-3.0-fast-generate-001' display_name='Veo 3 fast' description='Veo 3 fast' version='3.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/veo-3.1-generate-preview' display_name='Veo 3.1' description='Veo 3.1' version='3.1' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/veo-3.1-fast-generate-preview' display_name='Veo 3.1 fast' description='Veo 3.1 fast' version='3.1' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/gemini-2.5-flash-native-audio-latest' display_name='Gemini 2.5 Flash Native Audio Latest' description='Latest release of Gemini 2.5 Flash Native Audio' version='Gemini 2.5 Flash Native Audio Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-native-audio-preview-09-2025' display_name='Gemini 2.5 Flash Native Audio Preview 09-2025' description='Gemini 2.5 Flash Native Audio Preview 09-2025' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-native-audio-preview-12-2025' display_name='Gemini 2.5 Flash Native Audio Preview 12-2025' description='Gemini 2.5 Flash Native Audio Preview 12-2025' version='12-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from PIL import Image\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('MehmetKunur'))\n",
        "for model in client.models.list():\n",
        "  print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SSSiZMSAZVA"
      },
      "source": [
        "Ücretli API ile görüntü oluşturma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "collapsed": true,
        "id": "0reCN4hG_Q__",
        "outputId": "54993c89-4158-4980-cb99-dea175eb5c90"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\\nPlease retry in 20.230926325s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-preview-image'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-preview-image'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-preview-image'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4237370855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MehmetKunur'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m response=client.models.generate_content(model=\"gemini-2.5-flash-image\",\n\u001b[0m\u001b[1;32m      7\u001b[0m                                         contents=\"Create a picture of a Futuristic banana with neon lights\")\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5225\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5226\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5227\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   5228\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5229\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4007\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4009\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   4010\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4011\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[0;32m-> 1386\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m     response_body = (\n\u001b[1;32m   1388\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m   async def _async_request_once(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1197\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m       )\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m       return HttpResponse(\n\u001b[1;32m   1201\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody_segments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-flash-preview-image\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-flash-preview-image\\nPlease retry in 20.230926325s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-preview-image'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPe..."
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from PIL import Image\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('MehmetKunur'))\n",
        "\n",
        "response=client.models.generate_content(model=\"gemini-2.5-flash-image\",\n",
        "                                        contents=\"Create a picture of a Futuristic banana with neon lights\")\n",
        "\n",
        "for part in response.parts:\n",
        "  if part.inline_data:\n",
        "    image=part.as_image()\n",
        "    image.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n_n1GqYzAqfM",
        "outputId": "95b50506-8676-4f28-aa3c-193c81be7a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing Gemini models:\n",
            "name='models/gemini-2.5-flash' display_name='Gemini 2.5 Flash' description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-pro' display_name='Gemini 2.5 Pro' description='Stable release (June 17th, 2025) of Gemini 2.5 Pro' version='2.5' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-exp-image-generation' display_name='Gemini 2.0 Flash (Image Generation) Experimental' description='Gemini 2.0 Flash (Image Generation) Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=40 thinking=None\n",
            "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-flash-latest' display_name='Gemini Flash Latest' description='Latest release of Gemini Flash' version='Gemini Flash Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-flash-lite-latest' display_name='Gemini Flash-Lite Latest' description='Latest release of Gemini Flash-Lite' version='Gemini Flash-Lite Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-pro-latest' display_name='Gemini Pro Latest' description='Latest release of Gemini Pro' version='Gemini Pro Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-lite' display_name='Gemini 2.5 Flash-Lite' description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-image' display_name='Nano Banana' description='Gemini 2.5 Flash Preview Image' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=32768 output_token_limit=32768 supported_actions=['generateContent', 'countTokens', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=1.0 top_p=0.95 top_k=64 thinking=None\n",
            "name='models/gemini-2.5-flash-preview-09-2025' display_name='Gemini 2.5 Flash Preview Sep 2025' description='Gemini 2.5 Flash Preview Sep 2025' version='Gemini 2.5 Flash Preview 09-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-lite-preview-09-2025' display_name='Gemini 2.5 Flash-Lite Preview Sep 2025' description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite' version='2.5-preview-09-25' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-pro-preview' display_name='Gemini 3 Pro Preview' description='Gemini 3 Pro Preview' version='3-pro-preview-11-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-flash-preview' display_name='Gemini 3 Flash Preview' description='Gemini 3 Flash Preview' version='3-flash-preview-12-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-3-pro-image-preview' display_name='Nano Banana Pro' description='Gemini 3 Pro Image Preview' version='3.0' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=32768 supported_actions=['generateContent', 'countTokens', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=1.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-robotics-er-1.5-preview' display_name='Gemini Robotics-ER 1.5 Preview' description='Gemini Robotics-ER 1.5 Preview' version='1.5-preview' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-computer-use-preview-10-2025' display_name='Gemini 2.5 Computer Use Preview 10-2025' description='Gemini 2.5 Computer Use Preview 10-2025' version='Gemini 2.5 Computer Use Preview 10-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=65536 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-embedding-001' display_name='Gemini Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent'] default_checkpoint_id=None checkpoints=None temperature=None max_temperature=None top_p=None top_k=None thinking=None\n",
            "name='models/gemini-2.5-flash-native-audio-latest' display_name='Gemini 2.5 Flash Native Audio Latest' description='Latest release of Gemini 2.5 Flash Native Audio' version='Gemini 2.5 Flash Native Audio Latest' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-native-audio-preview-09-2025' display_name='Gemini 2.5 Flash Native Audio Preview 09-2025' description='Gemini 2.5 Flash Native Audio Preview 09-2025' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n",
            "name='models/gemini-2.5-flash-native-audio-preview-12-2025' display_name='Gemini 2.5 Flash Native Audio Preview 12-2025' description='Gemini 2.5 Flash Native Audio Preview 12-2025' version='12-2025' endpoints=None labels=None tuned_model_info=TunedModelInfo() input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None temperature=1.0 max_temperature=2.0 top_p=0.95 top_k=64 thinking=True\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('MehmetKunur'))\n",
        "\n",
        "print('Listing Gemini models:')\n",
        "for model in client.models.list():\n",
        "  if 'gemini' in model.name:\n",
        "    print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b73ad555"
      },
      "source": [
        "# Task\n",
        "Create an arithmetic game with a Gradio interface. The game should generate 10 random arithmetic questions (addition, subtraction, multiplication, division). Implement game logic to display questions, accept user answers, keep score, and provide feedback using `gemini-2.5-flash` for dynamic messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e53d876"
      },
      "source": [
        "## Install Gradio Library\n",
        "\n",
        "### Subtask:\n",
        "Install the Gradio library to create the web interface for the game.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aff5b082"
      },
      "source": [
        "**Reasoning**:\n",
        "To fulfill the subtask of installing the Gradio library, I will use a code cell to execute the `pip install gradio` command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66a322ad"
      },
      "outputs": [],
      "source": [
        "get_ipython().system('pip install gradio -q')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9acf7030"
      },
      "source": [
        "## Generate Arithmetic Questions\n",
        "\n",
        "### Subtask:\n",
        "Define a Python function to generate 10 random arithmetic questions (addition, subtraction, multiplication, division) along with their correct answers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0e304b"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate random arithmetic questions, I will implement a Python function that creates two random numbers, selects a random operation, constructs the question string, calculates the answer, and handles division specifics like integer results and avoiding division by zero. This function will be called 10 times to generate the required questions and answers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00c0efbe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_question():\n",
        "    while True:\n",
        "        num1 = random.randint(1, 100)\n",
        "        num2 = random.randint(1, 100)\n",
        "        operation = random.choice(['+', '-', '*', '/'])\n",
        "\n",
        "        if operation == '/':\n",
        "            if num2 == 0:\n",
        "                continue  # Avoid division by zero\n",
        "            if num1 % num2 != 0:\n",
        "                continue  # Ensure integer division result\n",
        "            answer = num1 // num2\n",
        "        elif operation == '+':\n",
        "            answer = num1 + num2\n",
        "        elif operation == '-':\n",
        "            answer = num1 - num2\n",
        "        elif operation == '*':\n",
        "            answer = num1 * num2\n",
        "\n",
        "        question = f\"{num1} {operation} {num2}\"\n",
        "        return question, answer\n",
        "\n",
        "questions_and_answers = []\n",
        "for _ in range(10):\n",
        "    question, answer = generate_question()\n",
        "    questions_and_answers.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "print(\"Generated 10 arithmetic questions:\")\n",
        "for item in questions_and_answers:\n",
        "    print(f\"Question: {item['question']}, Answer: {item['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f8f3fd3"
      },
      "source": [
        "## Set up Gradio Interface\n",
        "\n",
        "### Subtask:\n",
        "Create a Gradio interface with input/output components to display questions, accept user answers, and show game progress and results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97cf0e0"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the `gradio` library, define a global `game_state` dictionary, and then create the `start_game` and `submit_answer` functions as specified in the instructions. After that, I will construct the Gradio interface using `gr.Blocks` to arrange the input and output components and set up event listeners.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c81cb91"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# 2. Define a global variable game_state\n",
        "game_state = {\n",
        "    \"questions\": [],\n",
        "    \"current_question_index\": 0,\n",
        "    \"score\": 0,\n",
        "    \"total_questions\": 10 # Assuming 10 questions as per problem description\n",
        "}\n",
        "\n",
        "# 3. Define a function start_game\n",
        "def start_game():\n",
        "    global game_state\n",
        "    game_state[\"questions\"] = questions_and_answers # Use the globally generated questions\n",
        "    game_state[\"current_question_index\"] = 0\n",
        "    game_state[\"score\"] = 0\n",
        "    current_question = game_state[\"questions\"][0][\"question\"]\n",
        "    return current_question, \"Game started! Answer the first question.\", \"Score: 0/10\"\n",
        "\n",
        "# 4. Define a function submit_answer (placeholder for now)\n",
        "def submit_answer(user_answer):\n",
        "    # This is a placeholder. Actual logic for checking answer and updating score will be added later.\n",
        "    return \"Your answer was: \" + str(user_answer), \"Feedback will go here.\", \"Score: Not yet implemented.\"\n",
        "\n",
        "\n",
        "# 5. Create a Gradio interface using gr.Blocks\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Arithmetic Game\")\n",
        "\n",
        "    with gr.Row():\n",
        "        question_output = gr.Textbox(label=\"Question\", interactive=False)\n",
        "        feedback_output = gr.Textbox(label=\"Feedback\", interactive=False)\n",
        "    with gr.Row():\n",
        "        score_output = gr.Textbox(label=\"Score\", interactive=False)\n",
        "    with gr.Row():\n",
        "        user_answer_input = gr.Textbox(label=\"Your Answer\", placeholder=\"Enter your answer here\")\n",
        "    with gr.Row():\n",
        "        submit_button = gr.Button(\"Submit Answer\")\n",
        "        start_button = gr.Button(\"Start New Game\")\n",
        "\n",
        "    # Set up event listeners\n",
        "    start_button.click(start_game, outputs=[question_output, feedback_output, score_output])\n",
        "    submit_button.click(submit_answer, inputs=user_answer_input, outputs=[user_answer_input, feedback_output, score_output])\n",
        "\n",
        "# 9. Launch the Gradio interface\n",
        "demo.launch(debug=True, share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxtebBZmDUdDkrZRgk8CWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}